# ğŸ“š BookOnTheTable

**BookOnTheTable** is a web application built with **FastAPI** that offers a **public RESTful API** for querying books, including features such as authentication, categorization, statistics, automated scraping, and endpoints designed for consumption by Machine Learning models.

> You can find all the challenge requirements and details in the official document:  
[Tech Challenge - Phase 1 - Machine Learning Engineering (PDF)](https://github.com/LucasTechAI/BookOnTheTable/blob/main/docs/Pos_tech%20-%20Tech%20Challenge%20-%20Fase%201%20-%20Machine%20Learning%20Engineering.pdf)

---

## ğŸŒ Public URL

Access the public API hosted on Vercel:

- ğŸ”— **API:** [https://book-on-the-table.vercel.app](https://book-on-the-table.vercel.app)  
- ğŸ“‘ **Swagger UI:** [https://book-on-the-table.vercel.app/docs](https://book-on-the-table.vercel.app/docs)  
- ğŸ“˜ **Redoc:** [https://book-on-the-table.vercel.app/redoc](https://book-on-the-table.vercel.app/redoc)  

---

## ğŸ§© Project Structure

```bash
BookOnTheTable/
â”œâ”€â”€ data/
â”‚   â””â”€â”€ books_data.csv           # Extracted book data from scraping
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ Pipeline.png             # System architecture diagram
â”‚   â””â”€â”€ Pos_tech - Tech Challenge - Fase 1 - Machine Learning Engineering.pdf
â”œâ”€â”€ LICENSE                      # MIT License
â”œâ”€â”€ main.py                      # Main API entry point
â”œâ”€â”€ README.md                    # Project documentation
â”œâ”€â”€ requirements.txt             # Main API dependencies
â”œâ”€â”€ setup/                       # Helper scripts and configurations
â”‚   â”œâ”€â”€ creator.sql             # Database creation script
â”‚   â”œâ”€â”€ format_api.sh           # API code formatter
â”‚   â”œâ”€â”€ format_scraper.sh       # Scraper code formatter
â”‚   â””â”€â”€ format_utils.sh         # Utils code formatter
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ api/                     # FastAPI application
â”‚   â”‚   â”œâ”€â”€ app.py              # FastAPI app configuration
â”‚   â”‚   â”œâ”€â”€ config.py           # API configuration settings
â”‚   â”‚   â”œâ”€â”€ middleware/         # Custom middleware
â”‚   â”‚   â”‚   â””â”€â”€ logging_middleware.py
â”‚   â”‚   â”œâ”€â”€ routes/             # API endpoints
â”‚   â”‚   â”‚   â”œâ”€â”€ auth.py         # Authentication routes
â”‚   â”‚   â”‚   â”œâ”€â”€ books.py        # Book-related endpoints
â”‚   â”‚   â”‚   â”œâ”€â”€ categories.py   # Category endpoints
â”‚   â”‚   â”‚   â”œâ”€â”€ health.py       # Health check endpoints
â”‚   â”‚   â”‚   â”œâ”€â”€ home.py         # Home/root endpoints
â”‚   â”‚   â”‚   â”œâ”€â”€ logs.py         # Logging endpoints
â”‚   â”‚   â”‚   â”œâ”€â”€ ml.py           # Machine Learning endpoints
â”‚   â”‚   â”‚   â””â”€â”€ stats.py        # Statistics endpoints
â”‚   â”‚   â”œâ”€â”€ schemas/            # Pydantic models for validation
â”‚   â”‚   â”‚   â”œâ”€â”€ auth_schema.py
â”‚   â”‚   â”‚   â”œâ”€â”€ books_schema.py
â”‚   â”‚   â”‚   â”œâ”€â”€ categories_schema.py
â”‚   â”‚   â”‚   â”œâ”€â”€ health_schema.py
â”‚   â”‚   â”‚   â”œâ”€â”€ logs_schema.py
â”‚   â”‚   â”‚   â”œâ”€â”€ ml_schema.py
â”‚   â”‚   â”‚   â””â”€â”€ stats_schema.py
â”‚   â”‚   â”œâ”€â”€ services/           # Business logic layer
â”‚   â”‚   â”‚   â”œâ”€â”€ auth_service.py
â”‚   â”‚   â”‚   â”œâ”€â”€ book_service.py
â”‚   â”‚   â”‚   â”œâ”€â”€ category_service.py
â”‚   â”‚   â”‚   â”œâ”€â”€ health_service.py
â”‚   â”‚   â”‚   â”œâ”€â”€ log_service.py
â”‚   â”‚   â”‚   â”œâ”€â”€ ml_service.py
â”‚   â”‚   â”‚   â””â”€â”€ stats_service.py
â”‚   â”‚   â””â”€â”€ utils/              # API utilities
â”‚   â”‚       â”œâ”€â”€ cache.py        # Caching utilities
â”‚   â”‚       â””â”€â”€ jwt_handler.py  # JWT token handling
â”‚   â”œâ”€â”€ dashboards/             # Streamlit monitoring dashboard
â”‚   â”‚   â”œâ”€â”€ app.py              # Dashboard main entry point
â”‚   â”‚   â”œâ”€â”€ api_client.py       # API communication client
â”‚   â”‚   â”œâ”€â”€ charts.py           # Interactive charts with Plotly
â”‚   â”‚   â”œâ”€â”€ components.py       # Reusable UI components
â”‚   â”‚   â”œâ”€â”€ config.py           # Dashboard configuration
â”‚   â”‚   â”œâ”€â”€ data_processing.py  # Data processing utilities
â”‚   â”‚   â”œâ”€â”€ pages.py            # Dashboard pages
â”‚   â”‚   â”œâ”€â”€ styles.py           # CSS styling
â”‚   â”‚   â”œâ”€â”€ requirements.txt    # Dashboard-specific dependencies
â”‚   â”‚   â””â”€â”€ img/                # Dashboard assets
â”‚   â”‚       â”œâ”€â”€ logo.png        # Project logo
â”‚   â”‚       â””â”€â”€ my.jpeg         # Profile image
â”‚   â”œâ”€â”€ scraper/                # Web scraper using BeautifulSoup
â”‚   â”‚   â”œâ”€â”€ main.py             # Scraper entry point
â”‚   â”‚   â””â”€â”€ scraping.py         # Scraping logic
â”‚   â””â”€â”€ test/                   # Automated tests
â”‚       â”œâ”€â”€ all_routes.py       # Complete API testing
â”‚       â””â”€â”€ random_routes.py    # Random endpoint testing
â”œâ”€â”€ tmp/
â”‚   â””â”€â”€ bookonthetable.db       # SQLite database file
â”œâ”€â”€ utils/                      # General utilities
â”‚   â”œâ”€â”€ database_manager.py     # Database operations
â”‚   â””â”€â”€ handler_api.py          # API request handlers
â””â”€â”€ vercel.json                 # Vercel deployment configuration
```

---

## ğŸ—ï¸ System Architecture

The following diagram shows the complete system architecture and data flow of the BookOnTheTable platform:

![System Architecture](docs/Pipeline.png)

---


## ğŸš€ How to run the API locally

1. **Clone the repository**

```bash
git clone https://github.com/LucasTechAI/BookOnTheTable.git
cd BookOnTheTable
```

2. **Create and activate a virtual environment**

```bash
python3 -m venv venv
source venv/bin/activate      # Linux/macOS
venv\Scripts\activate       # Windows
```

3. **Install the dependencies**

```bash
pip install -r requirements.txt
```
4. **Run the application**

```bash
PYTHONPATH=. uvicorn src.api.app:app --reload
```

API Docs available locally at:  
ğŸ“‘ http://127.0.0.1:8000/docs

---

## âœ… Features

### ğŸ”— API Features
- JWT-based authentication (login, register, refresh)
- Book listing and search with advanced filtering
- Category management and filtering
- General and category-specific statistics
- ML-ready endpoints (features, training data, predictions)
- Automated scraping from books.toscrape.com
- Structured logging via middleware
- Continuous deployment on Vercel

### ğŸ“Š Dashboard Features
- Real-time API monitoring and log analysis
- Interactive data visualization with Plotly
- Performance metrics and response time tracking
- Endpoint usage analytics and patterns
- User activity and IP address monitoring
- Advanced filtering and search capabilities
- System health and uptime monitoring
- Secure authentication and access control

---

## ğŸ“¡ Main Endpoints

### Books
- GET /api/v1/books
- GET /api/v1/books/{id}
- GET /api/v1/books/search?title=...&category=...
- GET /api/v1/books/top-rated
- GET /api/v1/books/price-range?min=10&max=50

### Categories
- GET /api/v1/categories

### Health & Logs
- GET /api/v1/health
- GET /api/v1/logs
- DELETE /api/v1/logs

### Authentication
- POST /api/v1/auth/register
- POST /api/v1/auth/login
- POST /api/v1/auth/refresh
- GET /api/v1/auth/protected

### Machine Learning
- GET /api/v1/ml/features
- GET /api/v1/ml/training-data
- POST /api/v1/ml/predictions
  
---

## ğŸ“Š Dashboard - Real-time API Monitoring

The project includes a comprehensive **Streamlit dashboard** for real-time API monitoring and log analysis.
### Features:
- ğŸ“ˆ Real-time API performance monitoring with Plotly
- ğŸ¯ Endpoint usage analytics
- ğŸ‘¥ User activity tracking
- ğŸ” Advanced filtering capabilities
- âš¡ System health monitoring

### Running the Dashboard Locally:

**Note:** The dashboard requires additional dependencies that exceed Vercel's size limits, so it runs separately.

1. **Navigate to the dashboard directory:**
```bash
cd src/dashboards
```

2. **Install dashboard-specific dependencies:**
```bash
pip install -r requirements.txt
```

3. **Run the Streamlit dashboard:**
```bash
streamlit run app.py
```

The dashboard will be available at: http://localhost:8501

### Why Separate Requirements?
- Streamlit and Plotly dependencies are heavy (~100MB+)
- Vercel has deployment size limitations for serverless functions
- The main API remains lightweight for optimal performance
- Dashboard can be deployed separately on Streamlit Cloud or other platforms

---

## ğŸ•·ï¸ Run Only the Scraper (Optional)

If you want to run the scraper separately to update or generate the `books_data.csv` file:

```bash
cd BookOnTheTable
python3 src/scraper/main.py
```

This will fetch all book data from [books.toscrape.com](https://books.toscrape.com/) and save it in `books_data.csv` for local use or further ML processing.

---

## ğŸ› ï¸ Tech Stack

- Python 3.10+
- FastAPI
- SQLite3
- BeautifulSoup
- Pydantic
- Uvicorn
- Vercel (deployment)
- JWT

---

## ğŸ“œ License

This project is licensed under the MIT License. See the LICENSE file for more details.

---

## ğŸ‘¨â€ğŸ’» Author

**Lucas Mendes**  
Mid-Level Data Scientist  
ğŸŒ https://musicmoodai.com.br  
ğŸ“§ lucas.mendestech@gmail.com
ğŸ”— https://www.linkedin.com/in/lucas-mendes-barbosa/